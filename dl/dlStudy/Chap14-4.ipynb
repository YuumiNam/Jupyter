{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e47d4a",
   "metadata": {},
   "source": [
    "## EarlyStopping을 이용해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727d32b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b481c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/wine.csv', header=None);\n",
    "X = df.iloc[:, :12];\n",
    "y = df.iloc[:, 12];\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18ac7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential();\n",
    "model.add(layers.Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(layers.Dense(12, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid')) # hidden layer가 2개 들어간 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6b2af9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT\\miniconda3\\envs\\ml-env\\lib\\site-packages\\keras\\engine\\data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 47ms/step - loss: 2.3604 - accuracy: 0.2797 - val_loss: 0.6426 - val_accuracy: 0.7131\n",
      "Epoch 2/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4559 - accuracy: 0.7801 - val_loss: 0.3748 - val_accuracy: 0.7623\n",
      "Epoch 3/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.7583 - val_loss: 0.4030 - val_accuracy: 0.7531\n",
      "Epoch 4/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.7547 - val_loss: 0.4074 - val_accuracy: 0.7531\n",
      "Epoch 5/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.7575 - val_loss: 0.3826 - val_accuracy: 0.7669\n",
      "Epoch 6/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3597 - accuracy: 0.7873 - val_loss: 0.3457 - val_accuracy: 0.8131\n",
      "Epoch 7/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3283 - accuracy: 0.8468 - val_loss: 0.3273 - val_accuracy: 0.8731\n",
      "Epoch 8/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3150 - accuracy: 0.8845 - val_loss: 0.3107 - val_accuracy: 0.8808\n",
      "Epoch 9/2000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.2966 - accuracy: 0.8879 - val_loss: 0.2939 - val_accuracy: 0.8869\n",
      "Epoch 10/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2776 - accuracy: 0.8981 - val_loss: 0.2734 - val_accuracy: 0.8992\n",
      "Epoch 11/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2586 - accuracy: 0.9148 - val_loss: 0.2553 - val_accuracy: 0.9123\n",
      "Epoch 12/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2413 - accuracy: 0.9212 - val_loss: 0.2417 - val_accuracy: 0.9162\n",
      "Epoch 13/2000\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.2292 - accuracy: 0.9248 - val_loss: 0.2298 - val_accuracy: 0.9200\n",
      "Epoch 14/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2187 - accuracy: 0.9279 - val_loss: 0.2210 - val_accuracy: 0.9208\n",
      "Epoch 15/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2088 - accuracy: 0.9302 - val_loss: 0.2142 - val_accuracy: 0.9238\n",
      "Epoch 16/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2000 - accuracy: 0.9333 - val_loss: 0.2079 - val_accuracy: 0.9262\n",
      "Epoch 17/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1960 - accuracy: 0.9343 - val_loss: 0.2063 - val_accuracy: 0.9269\n",
      "Epoch 18/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1911 - accuracy: 0.9341 - val_loss: 0.2039 - val_accuracy: 0.9269\n",
      "Epoch 19/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1894 - accuracy: 0.9338 - val_loss: 0.2034 - val_accuracy: 0.9246\n",
      "Epoch 20/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1879 - accuracy: 0.9351 - val_loss: 0.2013 - val_accuracy: 0.9277\n",
      "Epoch 21/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1866 - accuracy: 0.9361 - val_loss: 0.2000 - val_accuracy: 0.9277\n",
      "Epoch 22/2000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.1857 - accuracy: 0.9348 - val_loss: 0.1980 - val_accuracy: 0.9292\n",
      "Epoch 23/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1846 - accuracy: 0.9356 - val_loss: 0.1971 - val_accuracy: 0.9292\n",
      "Epoch 24/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1824 - accuracy: 0.9348 - val_loss: 0.1959 - val_accuracy: 0.9292\n",
      "Epoch 25/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1816 - accuracy: 0.9356 - val_loss: 0.1944 - val_accuracy: 0.9315\n",
      "Epoch 26/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1801 - accuracy: 0.9364 - val_loss: 0.1930 - val_accuracy: 0.9315\n",
      "Epoch 27/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1792 - accuracy: 0.9366 - val_loss: 0.1921 - val_accuracy: 0.9315\n",
      "Epoch 28/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1778 - accuracy: 0.9369 - val_loss: 0.1909 - val_accuracy: 0.9308\n",
      "Epoch 29/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1758 - accuracy: 0.9374 - val_loss: 0.1899 - val_accuracy: 0.9308\n",
      "Epoch 30/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1743 - accuracy: 0.9361 - val_loss: 0.1879 - val_accuracy: 0.9331\n",
      "Epoch 31/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1735 - accuracy: 0.9379 - val_loss: 0.1864 - val_accuracy: 0.9331\n",
      "Epoch 32/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1724 - accuracy: 0.9376 - val_loss: 0.1853 - val_accuracy: 0.9331\n",
      "Epoch 33/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1709 - accuracy: 0.9394 - val_loss: 0.1845 - val_accuracy: 0.9323\n",
      "Epoch 34/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1694 - accuracy: 0.9387 - val_loss: 0.1823 - val_accuracy: 0.9338\n",
      "Epoch 35/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1672 - accuracy: 0.9389 - val_loss: 0.1815 - val_accuracy: 0.9346\n",
      "Epoch 36/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1659 - accuracy: 0.9400 - val_loss: 0.1795 - val_accuracy: 0.9338\n",
      "Epoch 37/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1645 - accuracy: 0.9392 - val_loss: 0.1777 - val_accuracy: 0.9346\n",
      "Epoch 38/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1634 - accuracy: 0.9389 - val_loss: 0.1757 - val_accuracy: 0.9338\n",
      "Epoch 39/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1629 - accuracy: 0.9425 - val_loss: 0.1751 - val_accuracy: 0.9338\n",
      "Epoch 40/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1624 - accuracy: 0.9394 - val_loss: 0.1742 - val_accuracy: 0.9338\n",
      "Epoch 41/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1593 - accuracy: 0.9415 - val_loss: 0.1714 - val_accuracy: 0.9338\n",
      "Epoch 42/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1564 - accuracy: 0.9412 - val_loss: 0.1709 - val_accuracy: 0.9331\n",
      "Epoch 43/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1556 - accuracy: 0.9425 - val_loss: 0.1685 - val_accuracy: 0.9369\n",
      "Epoch 44/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1534 - accuracy: 0.9425 - val_loss: 0.1667 - val_accuracy: 0.9354\n",
      "Epoch 45/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1523 - accuracy: 0.9423 - val_loss: 0.1647 - val_accuracy: 0.9377\n",
      "Epoch 46/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1500 - accuracy: 0.9433 - val_loss: 0.1635 - val_accuracy: 0.9369\n",
      "Epoch 47/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1485 - accuracy: 0.9448 - val_loss: 0.1611 - val_accuracy: 0.9369\n",
      "Epoch 48/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1470 - accuracy: 0.9435 - val_loss: 0.1598 - val_accuracy: 0.9377\n",
      "Epoch 49/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1454 - accuracy: 0.9448 - val_loss: 0.1576 - val_accuracy: 0.9377\n",
      "Epoch 50/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1432 - accuracy: 0.9451 - val_loss: 0.1563 - val_accuracy: 0.9385\n",
      "Epoch 51/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1412 - accuracy: 0.9461 - val_loss: 0.1552 - val_accuracy: 0.9415\n",
      "Epoch 52/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1409 - accuracy: 0.9492 - val_loss: 0.1560 - val_accuracy: 0.9385\n",
      "Epoch 53/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1389 - accuracy: 0.9487 - val_loss: 0.1506 - val_accuracy: 0.9415\n",
      "Epoch 54/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1362 - accuracy: 0.9482 - val_loss: 0.1493 - val_accuracy: 0.9408\n",
      "Epoch 55/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1344 - accuracy: 0.9489 - val_loss: 0.1477 - val_accuracy: 0.9454\n",
      "Epoch 56/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1330 - accuracy: 0.9492 - val_loss: 0.1469 - val_accuracy: 0.9431\n",
      "Epoch 57/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1314 - accuracy: 0.9494 - val_loss: 0.1439 - val_accuracy: 0.9508\n",
      "Epoch 58/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1288 - accuracy: 0.9505 - val_loss: 0.1419 - val_accuracy: 0.9508\n",
      "Epoch 59/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1269 - accuracy: 0.9507 - val_loss: 0.1405 - val_accuracy: 0.9492\n",
      "Epoch 60/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1263 - accuracy: 0.9500 - val_loss: 0.1398 - val_accuracy: 0.9515\n",
      "Epoch 61/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1241 - accuracy: 0.9551 - val_loss: 0.1394 - val_accuracy: 0.9515\n",
      "Epoch 62/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9523 - val_loss: 0.1503 - val_accuracy: 0.9585\n",
      "Epoch 63/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1307 - accuracy: 0.9523 - val_loss: 0.1336 - val_accuracy: 0.9531\n",
      "Epoch 64/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9528 - val_loss: 0.1366 - val_accuracy: 0.9515\n",
      "Epoch 65/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1192 - accuracy: 0.9548 - val_loss: 0.1307 - val_accuracy: 0.9562\n",
      "Epoch 66/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1164 - accuracy: 0.9538 - val_loss: 0.1311 - val_accuracy: 0.9585\n",
      "Epoch 67/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1159 - accuracy: 0.9564 - val_loss: 0.1287 - val_accuracy: 0.9562\n",
      "Epoch 68/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1130 - accuracy: 0.9584 - val_loss: 0.1274 - val_accuracy: 0.9569\n",
      "Epoch 69/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1113 - accuracy: 0.9564 - val_loss: 0.1256 - val_accuracy: 0.9592\n",
      "Epoch 70/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1102 - accuracy: 0.9595 - val_loss: 0.1241 - val_accuracy: 0.9577\n",
      "Epoch 71/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1088 - accuracy: 0.9582 - val_loss: 0.1225 - val_accuracy: 0.9592\n",
      "Epoch 72/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1071 - accuracy: 0.9587 - val_loss: 0.1215 - val_accuracy: 0.9631\n",
      "Epoch 73/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1059 - accuracy: 0.9607 - val_loss: 0.1204 - val_accuracy: 0.9592\n",
      "Epoch 74/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1046 - accuracy: 0.9605 - val_loss: 0.1195 - val_accuracy: 0.9592\n",
      "Epoch 75/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1035 - accuracy: 0.9607 - val_loss: 0.1182 - val_accuracy: 0.9592\n",
      "Epoch 76/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1025 - accuracy: 0.9605 - val_loss: 0.1166 - val_accuracy: 0.9600\n",
      "Epoch 77/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1015 - accuracy: 0.9605 - val_loss: 0.1152 - val_accuracy: 0.9638\n",
      "Epoch 78/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1010 - accuracy: 0.9620 - val_loss: 0.1142 - val_accuracy: 0.9646\n",
      "Epoch 79/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1004 - accuracy: 0.9628 - val_loss: 0.1151 - val_accuracy: 0.9685\n",
      "Epoch 80/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0983 - accuracy: 0.9623 - val_loss: 0.1117 - val_accuracy: 0.9654\n",
      "Epoch 81/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9636 - val_loss: 0.1151 - val_accuracy: 0.9723\n",
      "Epoch 82/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0973 - accuracy: 0.9654 - val_loss: 0.1097 - val_accuracy: 0.9685\n",
      "Epoch 83/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9648 - val_loss: 0.1110 - val_accuracy: 0.9631\n",
      "Epoch 84/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0928 - accuracy: 0.9687 - val_loss: 0.1077 - val_accuracy: 0.9677\n",
      "Epoch 85/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0926 - accuracy: 0.9648 - val_loss: 0.1104 - val_accuracy: 0.9754\n",
      "Epoch 86/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0919 - accuracy: 0.9656 - val_loss: 0.1057 - val_accuracy: 0.9692\n",
      "Epoch 87/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0903 - accuracy: 0.9692 - val_loss: 0.1055 - val_accuracy: 0.9669\n",
      "Epoch 88/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0890 - accuracy: 0.9682 - val_loss: 0.1061 - val_accuracy: 0.9669\n",
      "Epoch 89/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9684 - val_loss: 0.1063 - val_accuracy: 0.9654\n",
      "Epoch 90/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0873 - accuracy: 0.9690 - val_loss: 0.1022 - val_accuracy: 0.9731\n",
      "Epoch 91/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9687 - val_loss: 0.1023 - val_accuracy: 0.9754\n",
      "Epoch 92/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0854 - accuracy: 0.9720 - val_loss: 0.1011 - val_accuracy: 0.9723\n",
      "Epoch 93/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0837 - accuracy: 0.9723 - val_loss: 0.1007 - val_accuracy: 0.9700\n",
      "Epoch 94/2000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.0829 - accuracy: 0.9725 - val_loss: 0.0998 - val_accuracy: 0.9731\n",
      "Epoch 95/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0821 - accuracy: 0.9725 - val_loss: 0.0990 - val_accuracy: 0.9754\n",
      "Epoch 96/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0814 - accuracy: 0.9743 - val_loss: 0.0983 - val_accuracy: 0.9754\n",
      "Epoch 97/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 0.9725 - val_loss: 0.1005 - val_accuracy: 0.9792\n",
      "Epoch 98/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9728 - val_loss: 0.1011 - val_accuracy: 0.9792\n",
      "Epoch 99/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0821 - accuracy: 0.9707 - val_loss: 0.0969 - val_accuracy: 0.9762\n",
      "Epoch 100/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9741 - val_loss: 0.0992 - val_accuracy: 0.9685\n",
      "Epoch 101/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9725 - val_loss: 0.1010 - val_accuracy: 0.9677\n",
      "Epoch 102/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0778 - accuracy: 0.9761 - val_loss: 0.0965 - val_accuracy: 0.9738\n",
      "Epoch 103/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9736 - val_loss: 0.0969 - val_accuracy: 0.9708\n",
      "Epoch 104/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0762 - accuracy: 0.9759 - val_loss: 0.0952 - val_accuracy: 0.9754\n",
      "Epoch 105/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9756 - val_loss: 0.0971 - val_accuracy: 0.9723\n",
      "Epoch 106/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0750 - accuracy: 0.9759 - val_loss: 0.0947 - val_accuracy: 0.9754\n",
      "Epoch 107/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0763 - accuracy: 0.9736 - val_loss: 0.0936 - val_accuracy: 0.9769\n",
      "Epoch 108/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0738 - accuracy: 0.9751 - val_loss: 0.0948 - val_accuracy: 0.9785\n",
      "Epoch 109/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9761 - val_loss: 0.0955 - val_accuracy: 0.9785\n",
      "Epoch 110/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0731 - accuracy: 0.9743 - val_loss: 0.0926 - val_accuracy: 0.9754\n",
      "Epoch 111/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9774 - val_loss: 0.0929 - val_accuracy: 0.9769\n",
      "Epoch 112/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0707 - accuracy: 0.9772 - val_loss: 0.0921 - val_accuracy: 0.9762\n",
      "Epoch 113/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0700 - accuracy: 0.9784 - val_loss: 0.0919 - val_accuracy: 0.9754\n",
      "Epoch 114/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0693 - accuracy: 0.9787 - val_loss: 0.0915 - val_accuracy: 0.9746\n",
      "Epoch 115/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0685 - accuracy: 0.9779 - val_loss: 0.0913 - val_accuracy: 0.9769\n",
      "Epoch 116/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9782 - val_loss: 0.0921 - val_accuracy: 0.9785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0679 - accuracy: 0.9784 - val_loss: 0.0912 - val_accuracy: 0.9762\n",
      "Epoch 118/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9764 - val_loss: 0.0923 - val_accuracy: 0.9777\n",
      "Epoch 119/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9779 - val_loss: 0.0942 - val_accuracy: 0.9754\n",
      "Epoch 120/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9787 - val_loss: 0.0948 - val_accuracy: 0.9754\n",
      "Epoch 121/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0668 - accuracy: 0.9777 - val_loss: 0.0899 - val_accuracy: 0.9785\n",
      "Epoch 122/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0655 - accuracy: 0.9795 - val_loss: 0.0892 - val_accuracy: 0.9769\n",
      "Epoch 123/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9797 - val_loss: 0.0923 - val_accuracy: 0.9785\n",
      "Epoch 124/2000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0661 - accuracy: 0.9790 - val_loss: 0.1011 - val_accuracy: 0.9723\n",
      "Epoch 125/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0679 - accuracy: 0.9766 - val_loss: 0.0888 - val_accuracy: 0.9754\n",
      "Epoch 126/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9779 - val_loss: 0.0897 - val_accuracy: 0.9785\n",
      "Epoch 127/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0644 - accuracy: 0.9779 - val_loss: 0.0879 - val_accuracy: 0.9769\n",
      "Epoch 128/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0641 - accuracy: 0.9790 - val_loss: 0.0944 - val_accuracy: 0.9762\n",
      "Epoch 129/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0627 - accuracy: 0.9805 - val_loss: 0.0878 - val_accuracy: 0.9785\n",
      "Epoch 130/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9779 - val_loss: 0.0893 - val_accuracy: 0.9792\n",
      "Epoch 131/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0629 - accuracy: 0.9787 - val_loss: 0.0875 - val_accuracy: 0.9792\n",
      "Epoch 132/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9808 - val_loss: 0.0893 - val_accuracy: 0.9785\n",
      "Epoch 133/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0621 - accuracy: 0.9792 - val_loss: 0.0968 - val_accuracy: 0.9746\n",
      "Epoch 134/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9749 - val_loss: 0.0896 - val_accuracy: 0.9777\n",
      "Epoch 135/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9805 - val_loss: 0.0883 - val_accuracy: 0.9792\n",
      "Epoch 136/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0616 - accuracy: 0.9790 - val_loss: 0.0873 - val_accuracy: 0.9792\n",
      "Epoch 137/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9782 - val_loss: 0.0943 - val_accuracy: 0.9769\n",
      "Epoch 138/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9790 - val_loss: 0.0973 - val_accuracy: 0.9738\n",
      "Epoch 139/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9782 - val_loss: 0.0917 - val_accuracy: 0.9792\n",
      "Epoch 140/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0623 - accuracy: 0.9764 - val_loss: 0.0864 - val_accuracy: 0.9800\n",
      "Epoch 141/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0622 - accuracy: 0.9802 - val_loss: 0.0858 - val_accuracy: 0.9808\n",
      "Epoch 142/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9808 - val_loss: 0.0899 - val_accuracy: 0.9777\n",
      "Epoch 143/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9808 - val_loss: 0.0864 - val_accuracy: 0.9777\n",
      "Epoch 144/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9805 - val_loss: 0.0862 - val_accuracy: 0.9800\n",
      "Epoch 145/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.0849 - val_accuracy: 0.9815\n",
      "Epoch 146/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9795 - val_loss: 0.0902 - val_accuracy: 0.9777\n",
      "Epoch 147/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9820 - val_loss: 0.0855 - val_accuracy: 0.9800\n",
      "Epoch 148/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0558 - accuracy: 0.9800 - val_loss: 0.0843 - val_accuracy: 0.9815\n",
      "Epoch 149/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9815 - val_loss: 0.0848 - val_accuracy: 0.9823\n",
      "Epoch 150/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0851 - val_accuracy: 0.9800\n",
      "Epoch 151/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9815 - val_loss: 0.0849 - val_accuracy: 0.9800\n",
      "Epoch 152/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9805 - val_loss: 0.0844 - val_accuracy: 0.9823\n",
      "Epoch 153/2000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0553 - accuracy: 0.9820 - val_loss: 0.0841 - val_accuracy: 0.9823\n",
      "Epoch 154/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9810 - val_loss: 0.0853 - val_accuracy: 0.9808\n",
      "Epoch 155/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9828 - val_loss: 0.0851 - val_accuracy: 0.9800\n",
      "Epoch 156/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9792 - val_loss: 0.0870 - val_accuracy: 0.9777\n",
      "Epoch 157/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9818 - val_loss: 0.0846 - val_accuracy: 0.9823\n",
      "Epoch 158/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0550 - accuracy: 0.9813 - val_loss: 0.0856 - val_accuracy: 0.9808\n",
      "Epoch 159/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 0.9823 - val_loss: 0.0839 - val_accuracy: 0.9823\n",
      "Epoch 160/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0850 - val_accuracy: 0.9815\n",
      "Epoch 161/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9820 - val_loss: 0.0876 - val_accuracy: 0.9777\n",
      "Epoch 162/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9823 - val_loss: 0.0847 - val_accuracy: 0.9808\n",
      "Epoch 163/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9833 - val_loss: 0.0857 - val_accuracy: 0.9808\n",
      "Epoch 164/2000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0546 - accuracy: 0.9813 - val_loss: 0.0833 - val_accuracy: 0.9831\n",
      "Epoch 165/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.9833 - val_loss: 0.0868 - val_accuracy: 0.9777\n",
      "Epoch 166/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9802 - val_loss: 0.0952 - val_accuracy: 0.9777\n",
      "Epoch 167/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9813 - val_loss: 0.0835 - val_accuracy: 0.9808\n",
      "Epoch 168/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0524 - accuracy: 0.9818 - val_loss: 0.0829 - val_accuracy: 0.9823\n",
      "Epoch 169/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9823 - val_loss: 0.0830 - val_accuracy: 0.9831\n",
      "Epoch 170/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9833 - val_loss: 0.0833 - val_accuracy: 0.9823\n",
      "Epoch 171/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9833 - val_loss: 0.0830 - val_accuracy: 0.9831\n",
      "Epoch 172/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0503 - accuracy: 0.9833 - val_loss: 0.0827 - val_accuracy: 0.9831\n",
      "Epoch 173/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9815 - val_loss: 0.0829 - val_accuracy: 0.9831\n",
      "Epoch 174/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9828 - val_loss: 0.0830 - val_accuracy: 0.9831\n",
      "Epoch 175/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9818 - val_loss: 0.0830 - val_accuracy: 0.9831\n",
      "Epoch 176/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0509 - accuracy: 0.9831 - val_loss: 0.0826 - val_accuracy: 0.9831\n",
      "Epoch 177/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.0906 - val_accuracy: 0.9785\n",
      "Epoch 178/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9813 - val_loss: 0.0932 - val_accuracy: 0.9769\n",
      "Epoch 179/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9820 - val_loss: 0.0893 - val_accuracy: 0.9792\n",
      "Epoch 180/2000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0522 - accuracy: 0.9831 - val_loss: 0.0825 - val_accuracy: 0.9838\n",
      "Epoch 181/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9810 - val_loss: 0.0851 - val_accuracy: 0.9808\n",
      "Epoch 182/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9820 - val_loss: 0.0833 - val_accuracy: 0.9823\n",
      "Epoch 183/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0920 - val_accuracy: 0.9777\n",
      "Epoch 184/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9826 - val_loss: 0.0897 - val_accuracy: 0.9800\n",
      "Epoch 185/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.0836 - val_accuracy: 0.9823\n",
      "Epoch 186/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 0.9838 - val_loss: 0.0832 - val_accuracy: 0.9831\n",
      "Epoch 187/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9838 - val_loss: 0.0829 - val_accuracy: 0.9838\n",
      "Epoch 188/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.9851 - val_loss: 0.0831 - val_accuracy: 0.9823\n",
      "Epoch 189/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9833 - val_loss: 0.0914 - val_accuracy: 0.9800\n",
      "Epoch 190/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0520 - accuracy: 0.9828 - val_loss: 0.0906 - val_accuracy: 0.9800\n",
      "Epoch 191/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0506 - accuracy: 0.9836 - val_loss: 0.0845 - val_accuracy: 0.9823\n",
      "Epoch 192/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9838 - val_loss: 0.0829 - val_accuracy: 0.9823\n",
      "Epoch 193/2000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0473 - accuracy: 0.9849 - val_loss: 0.0844 - val_accuracy: 0.9831\n",
      "Epoch 194/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9846 - val_loss: 0.0835 - val_accuracy: 0.9823\n",
      "Epoch 195/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9856 - val_loss: 0.0841 - val_accuracy: 0.9823\n",
      "Epoch 196/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9833 - val_loss: 0.0827 - val_accuracy: 0.9838\n",
      "Epoch 197/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9838 - val_loss: 0.0830 - val_accuracy: 0.9838\n",
      "Epoch 198/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9846 - val_loss: 0.0841 - val_accuracy: 0.9815\n",
      "Epoch 199/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9836 - val_loss: 0.0831 - val_accuracy: 0.9831\n",
      "Epoch 200/2000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9854 - val_loss: 0.0889 - val_accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']);\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20) # validation loss를 감시하다가 20번 연속적으로 좋아지지 않는다면 강제로 학습을 중지\n",
    "model_path = \"./model/best_model.hdf5\"\n",
    "chackpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=0, save_best_only=True) # validation loss를 감시하다가 좋아졌을때에만(loss값이 적어질때만) 저장\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=2000, batch_size=500, verbose=1, validation_split=0.25, callbacks=[early_stopping, chackpoint]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0847dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.360402</td>\n",
       "      <td>0.279702</td>\n",
       "      <td>0.642590</td>\n",
       "      <td>0.713077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.455876</td>\n",
       "      <td>0.780087</td>\n",
       "      <td>0.374793</td>\n",
       "      <td>0.762308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.376200</td>\n",
       "      <td>0.758276</td>\n",
       "      <td>0.403017</td>\n",
       "      <td>0.753077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.398086</td>\n",
       "      <td>0.754683</td>\n",
       "      <td>0.407364</td>\n",
       "      <td>0.753077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.389034</td>\n",
       "      <td>0.757506</td>\n",
       "      <td>0.382643</td>\n",
       "      <td>0.766923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  2.360402  0.279702  0.642590      0.713077\n",
       "1  0.455876  0.780087  0.374793      0.762308\n",
       "2  0.376200  0.758276  0.403017      0.753077\n",
       "3  0.398086  0.754683  0.407364      0.753077\n",
       "4  0.389034  0.757506  0.382643      0.766923"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f299ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9GklEQVR4nO3de1yUZf7/8feAnFTA1DglClqejTxlaqmkaZqim6W1remvNdctI0U7qFuZbtp2MNdMO3mob+3qbp7Y1S3xK2ith/WARkpoSeA3IdNV8IgK9+8PZGJgGE4DM9y+no/HPIa57+ue+dzcg/P2uq77HothGIYAAABMwsPVBQAAADgT4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJgK4QYAAJhKPVcXUNsKCgp0/Phx+fv7y2KxuLocAABQAYZh6OzZswoLC5OHh+O+mesu3Bw/flzh4eGuLgMAAFTBsWPH1KxZM4dtrrtw4+/vL6nwlxMQEODiagAAQEXk5uYqPDzc+jnuyHUXboqGogICAgg3AADUMRWZUsKEYgAAYCqEGwAAYCqEGwAAYCrX3ZwbAIBr5efn68qVK64uA27I29u73NO8K4JwAwCoFYZhKDs7W2fOnHF1KXBTHh4eioyMlLe3d7Weh3ADAKgVRcEmKChI9evX50KqsFF0kd2srCw1b968Wu8Pwg0AoMbl5+dbg02TJk1cXQ7c1I033qjjx4/r6tWr8vLyqvLzMKEYAFDjiubY1K9f38WVwJ0VDUfl5+dX63kINwCAWsNQFBxx1vuDcAMAAEyFcAMAAEyFcAMAwHUqKSlJFovFdKfnE26cKD5emjKl8B4AUPdZLBaHt3HjxlX5uSMiIrRgwQKn1SpJ/fr10+TJk536nHURp4I7SXy8NHy45OkpLVggrV8vxcS4uioAQHVkZWVZf161apVefPFFpaWlWZf5+fm5oiyUg54bJ0lMLAw2+fmF90lJrq4IAEyslrrKQ0JCrLfAwEBZLBabZdu2bVPXrl3l6+urli1b6uWXX9bVq1et28+aNUvNmzeXj4+PwsLCFBsbK6mwhyUjI0NTpkyx9gJJUkZGhoYNG6YbbrhBDRo0UIcOHbRx40br8x06dEhDhgxRw4YNFRwcrDFjxujkyZOSpHHjxmnr1q3685//bH3OH374odL7vHr1anXo0EE+Pj6KiIjQm2++abN+8eLFuuWWW+Tr66vg4GA98MAD1nWfffaZOnXqJD8/PzVp0kQDBgzQ+fPnK11DdRFunCQ6+pdgk58v9evn6ooAwKSKusrffrvw3kVzAb744gv95je/UWxsrA4dOqT33ntPK1as0CuvvCKp8IP+rbfe0nvvvacjR45o3bp16tSpkyRpzZo1atasmWbPnq2srCxrD9GTTz6pvLw8bdu2TSkpKfrTn/6khg0bSirsRerbt69uu+027dmzR59//rl++uknjRo1SpL05z//WT179tTjjz9ufc7w8PBK7dPevXs1atQoPfTQQ0pJSdGsWbP0wgsvaMWKFZKkPXv2KDY2VrNnz1ZaWpo+//xz9enTx1rfww8/rMcee0ypqalKSkrS/fffL8Mwqv27riyGpZwkJqZwKCopqTDYMCQFADXEXle5C/7RfeWVV/T8889r7NixkqSWLVtqzpw5evbZZ/XSSy8pMzNTISEhGjBggLy8vNS8eXPdfvvtkqTGjRvL09NT/v7+CgkJsT5nZmamRo4caQ1BLVu2tK5bsmSJunTporlz51qXLVu2TOHh4Tp8+LBat24tb29v1a9f3+Y5K2P+/Pnq37+/XnjhBUlS69atdejQIb3++usaN26cMjMz1aBBAw0dOlT+/v5q0aKFOnfuLKkw3Fy9elX333+/WrRoIUnW/aht9Nw4UUyMNH8+wQYAapSbdJXv3btXs2fPVsOGDa23ol6TCxcu6MEHH9TFixfVsmVLPf7441q7dq3NkJU9sbGx+uMf/6jevXvrpZde0tdff23zeomJiTav17ZtW0nS999/75R9Sk1NVe/evW2W9e7dW0eOHFF+fr7uuecetWjRQi1bttSYMWP06aef6sKFC5KkqKgo9e/fX506ddKDDz6oDz74QKdPn3ZKXZVFuAEA1C1FXeWxsS49e6OgoEAvv/yy9u/fb72lpKToyJEj8vX1VXh4uNLS0vTOO+/Iz89PTzzxhPr06WP9Kgp7xo8fr6NHj2rMmDFKSUlRt27d9Pbbb1tfb9iwYTavt3//fh05csQ6NFRdhmGUukpw8WElf39/7du3T3/9618VGhqqF198UVFRUTpz5ow8PT2VkJCgf/3rX2rfvr3efvtttWnTRunp6U6prTIINwCAuscNusq7dOmitLQ03XzzzaVuHh6FH69+fn6KiYnRwoULlZSUpB07diglJUVS4fco2fsOpfDwcE2cOFFr1qzR1KlT9cEHH1hf7+DBg4qIiCj1eg0aNHD4nBXVvn17ffXVVzbLtm/frtatW8vT01OSVK9ePQ0YMECvvfaavv76a/3www/asmWLpMJT53v37q2XX35ZycnJ8vb21tq1a6tcT1Ux5wYAgCp48cUXNXToUIWHh+vBBx+Uh4eHvv76a6WkpOiPf/yjVqxYofz8fPXo0UP169fX//zP/8jPz886HyUiIkLbtm3TQw89JB8fHzVt2lSTJ0/W4MGD1bp1a50+fVpbtmxRu3btJBVONv7ggw/08MMP65lnnlHTpk313XffaeXKlfrggw/k6empiIgI7dq1Sz/88IMaNmyoxo0bW4NWRUydOlXdu3fXnDlzNHr0aO3YsUOLFi3S4sWLJUn//Oc/dfToUfXp00c33HCDNm7cqIKCArVp00a7du3S//7v/2rgwIEKCgrSrl279PPPP1vrr1XGdSYnJ8eQZOTk5Li6FAC4bly8eNE4dOiQcfHiRVeXUmXLly83AgMDbZZ9/vnnRq9evQw/Pz8jICDAuP32243333/fMAzDWLt2rdGjRw8jICDAaNCggXHHHXcYmzdvtm67Y8cO49ZbbzV8fHyMoo/jSZMmGa1atTJ8fHyMG2+80RgzZoxx8uRJ6zaHDx82fvWrXxmNGjUy/Pz8jLZt2xqTJ082CgoKDMMwjLS0NOOOO+4w/Pz8DElGenq6w31KTEw0JBmnT5+2Lvvss8+M9u3bG15eXkbz5s2N119/3bruyy+/NPr27WvccMMNhp+fn3Hrrbcaq1atMgzDMA4dOmQMGjTIuPHGGw0fHx+jdevWxttvv12p37Gj90llPr8thuGCc7RcKDc3V4GBgcrJyVFAQICrywGA68KlS5eUnp6uyMhI+fr6urocuClH75PKfH4z5wYAAJgK4QYAAJOaOHGizanjxW8TJ050dXk1hgnFAACY1OzZszVt2jS768w8NYNwAwCASQUFBSkoKMjVZdQ6hqUAAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAKhl/fr10+TJk11dhkMWi0Xr1q1zdRlVQrgBAKAMFovF4W3cuHFVet41a9Zozpw5zi3WgVmzZum2226rtddzNa5zAwBAGbKysqw/r1q1Si+++KLS0tKsy/z8/GzaX7lyRV5eXuU+b+PGjZ1XJEqh5wYAUOfEx0tTphTe16SQkBDrLTAwUBaLxfr40qVLatSokf72t7+pX79+8vX11SeffKJTp07p4YcfVrNmzVS/fn116tRJf/3rX22et+SwVEREhObOnavHHntM/v7+at68ud5//33r+suXL2vSpEkKDQ2Vr6+vIiIiNG/ePOv6nJwcTZgwQUFBQQoICNDdd9+tAwcOSJJWrFihl19+WQcOHLD2OK1YsaLSv4uUlBTdfffd8vPzU5MmTTRhwgSdO3fOuj4pKUm33367GjRooEaNGql3797KyMiQJB04cEDR0dHy9/dXQECAunbtqj179lS6hooi3AAA6pT4eGn4cOnttwvvazrglOe5555TbGysUlNTNWjQIF26dEldu3bVP//5T33zzTeaMGGCxowZo127djl8njfffFPdunVTcnKynnjiCf3+97/Xt99+K0lauHCh4uPj9be//U1paWn65JNPFBERIUkyDEP33XefsrOztXHjRu3du1ddunRR//799d///lejR4/W1KlT1aFDB2VlZSkrK0ujR4+u1D5euHBB9957r2644Qbt3r1bf//737V582ZNmjRJknT16lWNGDFCffv21ddff60dO3ZowoQJslgskqRHHnlEzZo10+7du7V37149//zzFerhqiqGpQAAdUpiouTpKeXnF94nJUkxMa6rZ/Lkybr//vttlhX/PqennnpKn3/+uf7+97+rR48eZT7PkCFD9MQTT0gqDExvvfWWkpKS1LZtW2VmZuqWW27RnXfeKYvFohYtWli3S0xMVEpKik6cOCEfHx9J0htvvKF169bps88+04QJE9SwYUPVq1dPISEhVdrHTz/9VBcvXtTHH3+sBg0aSJIWLVqkYcOG6U9/+pO8vLyUk5OjoUOHqlWrVpKkdu3aWbfPzMzUM888o7Zt20qSbrnllirVUVH03AAA6pTo6F+CTX6+1K+fa+vp1q2bzeP8/Hy98soruvXWW9WkSRM1bNhQmzZtUmZmpsPnufXWW60/Fw1/nThxQpI0btw47d+/X23atFFsbKw2bdpkbbt3716dO3fO+lpFt/T0dH3//fdO2cfU1FRFRUVZg40k9e7dWwUFBUpLS1Pjxo01btw4DRo0SMOGDdOf//xnm/lKcXFxGj9+vAYMGKBXX33VaXWVhXADAKhTYmKk9eul2NjCe1f22kiy+cCXCoeX3nrrLT377LPasmWL9u/fr0GDBuny5csOn6fkMI3FYlFBQYEkqUuXLkpPT9ecOXN08eJFjRo1Sg888IAkqaCgQKGhodq/f7/NLS0tTc8884xT9tEwDOsQU0lFy5cvX64dO3aoV69eWrVqlVq3bq2dO3dKKjxb6+DBg7rvvvu0ZcsWtW/fXmvXrnVKbfYwLAUAqHNiYlwfasry5Zdfavjw4frNb34jqTB8HDlyxGaYpioCAgI0evRojR49Wg888IDuvfde/fe//1WXLl2UnZ2tevXqWefhlOTt7a38/Pwqv3b79u310Ucf6fz589Yw9+9//1seHh5q3bq1tV3nzp3VuXNnTZ8+XT179tRf/vIX3XHHHZKk1q1bq3Xr1poyZYoefvhhLV++XL/61a+qXJMj9NwAAOBEN998sxISErR9+3alpqbqd7/7nbKzs6v1nG+99ZZWrlypb7/9VocPH9bf//53hYSEqFGjRhowYIB69uypESNG6IsvvtAPP/yg7du36w9/+IP1jKSIiAilp6dr//79OnnypPLy8ir1+o888oh8fX01duxYffPNN0pMTNRTTz2lMWPGKDg4WOnp6Zo+fbp27NihjIwMbdq0SYcPH1a7du108eJFTZo0SUlJScrIyNC///1v7d69u9phzxF6bgAAcKIXXnhB6enpGjRokOrXr68JEyZoxIgRysnJqfJzNmzYUH/605905MgReXp6qnv37tq4caM8PAr7KDZu3KiZM2fqscce088//6yQkBD16dNHwcHBkqSRI0dqzZo1io6O1pkzZ7R8+fJKXYCwfv36+uKLL/T000+re/fuql+/vkaOHKn58+db13/77bf66KOPdOrUKYWGhmrSpEn63e9+p6tXr+rUqVN69NFH9dNPP6lp06a6//779fLLL1f591Eei2EYRo09uxvKzc1VYGCgcnJyFBAQ4OpyAOC6cOnSJaWnpysyMlK+vr6uLgduytH7pDKf3wxLAQAAUyHcAABwnfn0009tThsvfuvQoYOry6s25twAAHCdiYmJKfOCgjV55eDaQrgBAOA64+/vL39/f1eXUWMYlgIA1Jqii9IB9jjrHCd6bgAANc7b21seHh46fvy4brzxRnl7e5d5xVtcnwzD0M8//yyLxVLtoTHCDQCgxnl4eCgyMlJZWVk6fvy4q8uBm7JYLGrWrJk8PT2r9TyEGwBArfD29lbz5s119erVan0VAMzLy8ur2sFGItwAAGpR0ZCDGc7IgftiQjEAADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVwg0AADAVl4abefPmqXv37vL391dQUJBGjBihtLS0crfbunWrunbtKl9fX7Vs2VLvvvtuLVQLAADqApeGm61bt+rJJ5/Uzp07lZCQoKtXr2rgwIE6f/58mdukp6dryJAhuuuuu5ScnKwZM2YoNjZWq1evrsXKAQCAu7IYhmG4uogiP//8s4KCgrR161b16dPHbpvnnntO8fHxSk1NtS6bOHGiDhw4oB07dpRqn5eXp7y8POvj3NxchYeHKycnRwEBAc7fCQAA4HS5ubkKDAys0Oe3W825ycnJkSQ1bty4zDY7duzQwIEDbZYNGjRIe/bs0ZUrV0q1nzdvngIDA6238PBw5xYNAADcituEG8MwFBcXpzvvvFMdO3Yss112draCg4NtlgUHB+vq1as6efJkqfbTp09XTk6O9Xbs2DGn1w4AANxHPVcXUGTSpEn6+uuv9dVXX5Xb1mKx2DwuGlkruVySfHx85OPj45wiAQCA23OLcPPUU08pPj5e27ZtU7NmzRy2DQkJUXZ2ts2yEydOqF69emrSpElNlgkAAOoAlw5LGYahSZMmac2aNdqyZYsiIyPL3aZnz55KSEiwWbZp0yZ169ZNXl5eNVUqAACoI1wabp588kl98skn+stf/iJ/f39lZ2crOztbFy9etLaZPn26Hn30UevjiRMnKiMjQ3FxcUpNTdWyZcu0dOlSTZs2zRW7AAAA3IxLw82SJUuUk5Ojfv36KTQ01HpbtWqVtU1WVpYyMzOtjyMjI7Vx40YlJSXptttu05w5c7Rw4UKNHDnSFbsAAADcjFtd56Y2VOY8eQAA4B7q7HVuAAAAqotwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATIVwAwAATMWl4Wbbtm0aNmyYwsLCZLFYtG7dOoftk5KSZLFYSt2+/fbb2ikYAAC4vXqufPHz588rKipK/+///T+NHDmywtulpaUpICDA+vjGG2+sifIAAEAd5NJwM3jwYA0ePLjS2wUFBalRo0bOLwgAANR5dXLOTefOnRUaGqr+/fsrMTHRYdu8vDzl5uba3AAAgHnVqXATGhqq999/X6tXr9aaNWvUpk0b9e/fX9u2bStzm3nz5ikwMNB6Cw8Pr8WKAQBAbbMYhmG4ughJslgsWrt2rUaMGFGp7YYNGyaLxaL4+Hi76/Py8pSXl2d9nJubq/DwcOXk5NjM2wEAAO4rNzdXgYGBFfr8rlM9N/bccccdOnLkSJnrfXx8FBAQYHMDAADmVefDTXJyskJDQ11dBgAAcBMuPVvq3Llz+u6776yP09PTtX//fjVu3FjNmzfX9OnT9eOPP+rjjz+WJC1YsEARERHq0KGDLl++rE8++USrV6/W6tWrXbULAADAzbg03OzZs0fR0dHWx3FxcZKksWPHasWKFcrKylJmZqZ1/eXLlzVt2jT9+OOP8vPzU4cOHbRhwwYNGTKk1msHAADuyW0mFNeWykxIAgAA7uG6mlAMAABQHOEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYCuEGAACYSpXCzUcffaQNGzZYHz/77LNq1KiRevXqpYyMDKcVBwAAUFlVCjdz586Vn5+fJGnHjh1atGiRXnvtNTVt2lRTpkxxaoEAAACVUa8qGx07dkw333yzJGndunV64IEHNGHCBPXu3Vv9+vVzZn0AAACVUqWem4YNG+rUqVOSpE2bNmnAgAGSJF9fX128eNF51QEAAFRSlXpu7rnnHo0fP16dO3fW4cOHdd9990mSDh48qIiICGfWBwAAUClV6rl555131LNnT/38889avXq1mjRpIknau3evHn74YacWCAAAUBkWwzAMVxdRm3JzcxUYGKicnBwFBAS4uhwAAFABlfn8rlLPzeeff66vvvrK+vidd97Rbbfdpl//+tc6ffp0VZ4SAADAKaoUbp555hnl5uZKklJSUjR16lQNGTJER48eVVxcnFMLBAAAqIwqTShOT09X+/btJUmrV6/W0KFDNXfuXO3bt09DhgxxaoEAAACVUaWeG29vb124cEGStHnzZg0cOFCS1LhxY2uPDgAAgCtUqefmzjvvVFxcnHr37q3//Oc/WrVqlSTp8OHDatasmVMLBAAAqIwq9dwsWrRI9erV02effaYlS5bopptukiT961//0r333uvUAgEAACqDU8EBAIDbq8znd5WGpSQpPz9f69atU2pqqiwWi9q1a6fhw4fL09Ozqk8JAABQbVUKN999952GDBmiH3/8UW3atJFhGDp8+LDCw8O1YcMGtWrVytl1AgAAVEiV5tzExsaqVatWOnbsmPbt26fk5GRlZmYqMjJSsbGxzq4RAACgwqrUc7N161bt3LlTjRs3ti5r0qSJXn31VfXu3dtpxQEAAFRWlXpufHx8dPbs2VLLz507J29v72oXBQAAUFVVCjdDhw7VhAkTtGvXLhmGIcMwtHPnTk2cOFExMTHOrhEAAKDCqhRuFi5cqFatWqlnz57y9fWVr6+vevXqpZtvvlkLFixwcokAAAAVV6U5N40aNdL69ev13XffKTU1VYZhqH379rr55pudXR8AAEClVDjclPdt30lJSdaf58+fX+WCAAAAqqPC4SY5OblC7SwWS5WLAQAAqK4Kh5vExMSarAMAAMApqjShGAAAwF0RbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKm4NNxs27ZNw4YNU1hYmCwWi9atW1fuNlu3blXXrl3l6+urli1b6t133635QgEAQJ3h0nBz/vx5RUVFadGiRRVqn56eriFDhuiuu+5ScnKyZsyYodjYWK1evbqGKwUAAHVFhb84syYMHjxYgwcPrnD7d999V82bN9eCBQskSe3atdOePXv0xhtvaOTIkXa3ycvLU15envVxbm5utWoGAADurU7NudmxY4cGDhxos2zQoEHas2ePrly5YnebefPmKTAw0HoLDw+vjVIBAICL1Klwk52dreDgYJtlwcHBunr1qk6ePGl3m+nTpysnJ8d6O3bsWG2UCgAAXMSlw1JVYbFYbB4bhmF3eREfHx/5+PjUeF0AAMA91Kmem5CQEGVnZ9ssO3HihOrVq6cmTZq4qCoAAOBO6lS46dmzpxISEmyWbdq0Sd26dZOXl5eLqgIAAO7EpeHm3Llz2r9/v/bv3y+p8FTv/fv3KzMzU1LhfJlHH33U2n7ixInKyMhQXFycUlNTtWzZMi1dulTTpk1zRfkAAMANuXTOzZ49exQdHW19HBcXJ0kaO3asVqxYoaysLGvQkaTIyEht3LhRU6ZM0TvvvKOwsDAtXLiwzNPAAQDA9cdiFM3IvU7k5uYqMDBQOTk5CggIcHU5AACgAirz+V2n5twAAACUh3ADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXDjTPHx0pQphfcAAMAlCDfOEh8vDR8uvf124T0BBwAAlyDcOEtiouTpKeXnF94nJbm6IgAArkuEG2eJjv4l2OTnS/36uboiAACuS/VcXYBpxMRI69cX9tj061f4GAAA1DrCjTPFxBBqAABwMYalAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqbg83CxevFiRkZHy9fVV165d9eWXX5bZNikpSRaLpdTt22+/rcWKAQCAO3NpuFm1apUmT56smTNnKjk5WXfddZcGDx6szMxMh9ulpaUpKyvLervllltqqWIAAODuXBpu5s+fr9/+9rcaP3682rVrpwULFig8PFxLlixxuF1QUJBCQkKsN09Pz1qqGAAAuDuXhZvLly9r7969GjhwoM3ygQMHavv27Q637dy5s0JDQ9W/f38lJiY6bJuXl6fc3FybGwAAMC+XhZuTJ08qPz9fwcHBNsuDg4OVnZ1td5vQ0FC9//77Wr16tdasWaM2bdqof//+2rZtW5mvM2/ePAUGBlpv4eHhTt0PAADgXuq5ugCLxWLz2DCMUsuKtGnTRm3atLE+7tmzp44dO6Y33nhDffr0sbvN9OnTFRcXZ32cm5tLwAEAwMRc1nPTtGlTeXp6luqlOXHiRKneHEfuuOMOHTlypMz1Pj4+CggIsLkBAADzclm48fb2VteuXZWQkGCzPCEhQb169arw8yQnJys0NNTZ5QEAgDrKpcNScXFxGjNmjLp166aePXvq/fffV2ZmpiZOnCipcEjpxx9/1McffyxJWrBggSIiItShQwddvnxZn3zyiVavXq3Vq1e7cjdKiY+XEhOl6GgpJsbV1QAAcH1xabgZPXq0Tp06pdmzZysrK0sdO3bUxo0b1aJFC0lSVlaWzTVvLl++rGnTpunHH3+Un5+fOnTooA0bNmjIkCGu2oVS4uOl4cMlT09pwQJp/XoCDgAAtcliGIbh6iJqU25urgIDA5WTk1Mj82+mTJHeflvKzy8MOLGx0vz5Tn8ZAACuK5X5/Hb51y+YTXT0L8EmP1/q18/VFQEAcH1x+angZhMTUzgUlZRUGGwYkgIAoHYRbmpATAyhBgAAV2FYCgAAmArhBgAAmArDUjWp+AVvJC5+AwBALSDc1JQSF7yJ1zAlWvoresGHilkvAg4AADWEcFNTEhOt54PHK0bDtV6exlUt0NMaNuUbjRf5BgCAmsCcm5pS7II3ieonT11V/rUs+c+j7TV8eGHnDgAAcC7CTU24Ntcm/oGPNeXW/1X9B4YoX/VkUYEkyZCHPHVVSUu/d3GhAACYD8NSznZtrk28x3ANL3hLnh4Fyk/20IwZ0jcrDyr+aCdrL04/JUlq5eqKAQAwFcKNs12ba5OY37cwxBTUk6endPGitP6tdMUPn6kky93yM84p0XhYimfuDQAAzsSwlLNdm2sT7bFV+apX2HNT9B1TMTGKWT9e/Yb5a67+oLc3tmLuDQAATkbPjbNd+3KpmKQkrffbpaSLPWy/YyomprBzx6NA+fke8vQoUFKSB703AAA4CeGmJlz7cqkYSfYyS3T9XVpQ0MM6bNXPb5ekHrVcJAAA5kS4cYGYCyu13mOekgr6qJ/HNsVcbCnCDQAAzsGcG1eIjlZMwXrN93xWMQXrFX+ss6Z02ar4mbtcXRkAAHUePTeucG1ejpKSFH+ss4Z/NkaeuqoFyfW0XrsU8wq9OAAAVBU9N64SEyPNn6/E75tbr3vjoXzN+jCMs6cAAKgGwo2LRQ/2tQabAnnqwImbOD0cAIBqINy4WMwrPbR+xi5FBfxwLeDw1QwAAFQH4cYNxLzSQ7P6JqpAntYhqu+SjjHBGACAKiDcuImY8UFarxjdpw2SpI25d2r43B4EHAAAKolw4y6ufTVDyxvPMcEYAIBqINy4k5gYRT9+MxOMAQCoBsKNm2GCMQAA1UO4cUP2Jhj7ZR/VlCn04AAAUB6uUOymYsYHaf0/YpRkuVt+xjnN/c8f5Lk7XwsWeGr9evEt4gAAlIGeG3d1bYLx/MmZutA9urAHx/BkiAoAgHIQbtzZta9oiA5JVb7qcQ0cAAAqgHBTB5R1DZyYkF2EHAAASiDc1AV2roEjSf/8qTsX+gMAoATCTV1R7Bo4FhVIkgx5FF7o760AAg4AANdYDMMwXF1EbcrNzVVgYKBycnIUEBDg6nIqLX7mLi1dKsX/1MN6ob+i+xm9EnXhooeiW2Uqptk+KTqa06oAAKZQmc9vwk0dFT9zl2a9FaADF1vbBJyiYav1lhGKMdZLw4ZJnTpJFy4Uhh1JSkyU6tf/ZRkBCADg5gg3Dpgl3EiFAWf43B4230VVFHSitF+D9S9dUANFK1ExHhukgsLhLHl4FP5cdD9smDR+fOG64sGn5D1BCADgIoQbB8wUbqTCgJP0+UX5+Rqauz3aGnAsypdRrEdnmNZrvJZJkhLVT/V1/pfgY/mnVPQ2KAo8FkvhsqL7ouUzZtgPPsUDkFQYkghDAAAnIdw4YLZwU1z8zF2a9WGYDvx8kwoMD0mGJIskyaICGdfmj5ecq1NW8Cl5H23ZWjjUVV4AkiRPTyk/33ZYzF4AolcIAFABhBsHzBxupMLvnho+vHjOKB5wDMkiGYZF5QWfop6fkj1AM/SKLqh+2QFISZIc9A4VD0AMjwEAKohw44DZw41UGHCSkiQ/P+mbbwofF3WkSLb5ooj94GN7X7LHp6wAJNnvHeqklIoFoOJFVmd4jAAEAKZBuHHgegg3JRWFnX79Ch9XJPiUlSk8LIYKHASgsnqHpALp2nV5HAUgpw6PEYAAwDQINw5cj+HGkbKCz8WL9u/nzq3YlBt7w2LlBSCnDo9VNwAxMRoA3ArhxgHCTfUUH/KyF4DK6h0qOb1GqvnhsSoHoKpMjK5MAIqPJzQBQCURbhwg3NS+koGoNobHqhuAis8LilaiYvSPwsKqe2ZYSor0j3/8ss369QQcAKgAwo0DhBv3VBPDY1UNQMXnBRVdILH4hOgqBSB73VQeHlJUlDRrVuFjenMAoEyEGwcIN+ZQ3vBYdQOQ7fCYVDQh2hkBKF7DlKjoa20aKlpbCoMR1wYCgDIRbhwg3Fw/qhqAineyFC0rVP0A1F27tFt2vvS0xPAY1wYCAFuEGwcINyiurABUNDy2dKnthOjqB6DSZ4+VDDrlXRvI7hCY5NyvziAcAXAzhBsHCDeoLOcHoF94WApUYHjYGR6T7F0byN4QmL2LItr0AOkfpXt8KnIef8l15fUSOQpHhCQA1US4cYBwg5pQ0QBUNK0mJkbq2NH+8Fj51waSHF0UsfSXpsZrvD6ULB5KNPpW/qszKtJL5CgcObMHydFp+MVPsS+5rq7j8gEA4cYRwg1cpfgZYSU/n+x9ZYa9awPZGwJzfG2gyl0csXibin51RrlnjxVXnR4kR6fhd+8u7d5tez2Byk7Qrm7IclZIK/6mKNp27tzyLx9QmQBUkbbFX/96vrBlbQZLZx9DZ27nBgg3DhBuUBeUdW2gkkNgjrJAcRaLJBkOL45Yla/OcHz2WLw66WtdUEPV1znrmWFl9SBZA5Hl2us6+qfJUZuy1lU1QFVnKK+i25cMYiWvh1T8gEdFSYMHlw5LxQNQ8UBX3rWW7A03FrWx90aramisjUBZkZ69ip6BGB8vffhh7VyXyt5rFR2X4vUU75kcPvyXtkW9oeUFlqJvVi7rfWLvtRwtq2zbaiLcOEC4QV1X3kURi4a6qnJxxOJtbJXfS1T22WOFPUdF84ukCgyhSUrU3dZQVPI+WltKtGlgc2q9/XVODFAVaeOs16hob1dZ11JyfGDtDzdWptaaCHs11bPn6H8FxeeWdepUGBZL/m6KB0tnBbGiYFryfyVFj2fMKB1IIyOljAzbuisSOmfNkg4cKPt9Yu+1iv8+ygvh9rZ3YiAk3DhAuMH1pDIXRyzZpiJfnVGZydNF68ruQSprCK1wWcVCUoEKyhiCq36Ast/GZsJ2VT+Ey/qlFf+A+9e/7H8w2XuN0r/06oWsyh3gmg17Nd3G3vFxtM4ZQaysUOnouBZfX9la7SnrtRz9Psrb3tNTio2V5s8ve7tKINw4QLgBKq6ivUSVPXvMuZ/FJXqQHKyTqhOg7LeZ8UCaLnyfrfp+Bbpw0cN6Hz3YV5KU+K9LpdaVarPyJ9U/+nXpANXyVkU/FCz16KHED79X/X/8tewg9sCDStwXqOijHyrGY4PiC+5Tou4uHcCK7m+/XfH/CVaipb+ijf+136b4zPfqHGBX9dyUFwpK/lxyfVHvQ8uW0g8/2LZzds9c0Wvdfrv0n/+UHpK0t91tt0n33mu/56esOjw8pIgI6ejR0se7qiHL0e+enpvaQbgBal55Z485ewit5gOUfWWNGFX5c7pkgKpIm2JBzDoKE5yh3T+1kKclX/mGZ+kA1ipEKXltCkcPHLS50KyN/RGW/6t8oLO3LrpVpmLCkyuWnqvSxtFpimV1VRYfYinebvjwinVjVuVNUPy1iuYHFdVVfDioZPApCg7x8RULncW3s/c7dPRaM2aU3Z1b9Hstvn1MjPTb3zLnprYQbgD3VJ0htNoMUBUdUXCHEZbi9TsKexWd1lO8bXVDZ8kpLjU257goiDkKa0XbX2sbPdi3sLfMzroq9cyV16bkaxWvcdeuwu2L6i+xP45CpzU8Fv+juBag7M2vjlG8TRu7p3ja684tua74Mici3DhAuAGuX84KUJX5Cg9XjsJUZLpERadUVDdkVWZaT23+ztzl2Dm7juLhsaInw5V1Caqqhk5nn21OuHGAcAPAmSo7BFeTbcoahXEUwBy1qckPanvcpbfLTHUUD7wVmU/srJBVdO/Ms+cJNw4QbgCYWUVGEhyNKNRUECtriktNTWOpahuz1FFcRXvNnD3E6uSTpQg3jhBuAMA9VOZsvNpsY4Y6HM0xK9lrVxNDrPTc1DLCDQDgeuBojpm9Ob/OHmJ19rziOhVuFi9erNdff11ZWVnq0KGDFixYoLvuuqvM9lu3blVcXJwOHjyosLAwPfvss5o4cWKFX49wAwBA3VOZz2+PWqrJrlWrVmny5MmaOXOmkpOTddddd2nw4MHKzMy02z49PV1DhgzRXXfdpeTkZM2YMUOxsbFavXp1LVcOAADclUt7bnr06KEuXbpoyZIl1mXt2rXTiBEjNG/evFLtn3vuOcXHxys1NdW6bOLEiTpw4IB27NhRodek5wYAgLqnTvTcXL58WXv37tXAgQNtlg8cOFDbt2+3u82OHTtKtR80aJD27NmjK1eu2N0mLy9Pubm5NjcAAGBeLgs3J0+eVH5+voKDg22WBwcHKzs72+422dnZdttfvXpVJ0+etLvNvHnzFBgYaL2Fh4c7ZwcAAIBbcumcG0myFJ0cf41hGKWWldfe3vIi06dPV05OjvV27NixalYMAADcWT1XvXDTpk3l6elZqpfmxIkTpXpnioSEhNhtX69ePTVp0sTuNj4+PvLx8XFO0QAAwO25rOfG29tbXbt2VUJCgs3yhIQE9erVy+42PXv2LNV+06ZN6tatm7y8vGqsVgAAUHe4dFgqLi5OH374oZYtW6bU1FRNmTJFmZmZ1uvWTJ8+XY8++qi1/cSJE5WRkaG4uDilpqZq2bJlWrp0qaZNm+aqXQAAAG7GZcNSkjR69GidOnVKs2fPVlZWljp27KiNGzeqRYsWkqSsrCyba95ERkZq48aNmjJlit555x2FhYVp4cKFGjlypKt2AQAAuBmXX6G4tnGdGwAA6p46cZ0bAACAmkC4AQAApuLSOTeuUDQKx5WKAQCoO4o+tysym+a6Czdnz56VJK5UDABAHXT27FkFBgY6bHPdTSguKCjQ8ePH5e/v7/BKyFWRm5ur8PBwHTt2zLSTlc2+j2bfP4l9NAOz759k/n00+/5Jzt9HwzB09uxZhYWFycPD8aya667nxsPDQ82aNavR1wgICDDtm7WI2ffR7PsnsY9mYPb9k8y/j2bfP8m5+1hej00RJhQDAABTIdwAAABTIdw4kY+Pj1566SVTf1Gn2ffR7PsnsY9mYPb9k8y/j2bfP8m1+3jdTSgGAADmRs8NAAAwFcINAAAwFcINAAAwFcINAAAwFcKNkyxevFiRkZHy9fVV165d9eWXX7q6pCqbN2+eunfvLn9/fwUFBWnEiBFKS0uzaTNu3DhZLBab2x133OGiiitn1qxZpWoPCQmxrjcMQ7NmzVJYWJj8/PzUr18/HTx40IUVV15ERESpfbRYLHryyScl1c3jt23bNg0bNkxhYWGyWCxat26dzfqKHLe8vDw99dRTatq0qRo0aKCYmBj93//9Xy3uRdkc7d+VK1f03HPPqVOnTmrQoIHCwsL06KOP6vjx4zbP0a9fv1LH9aGHHqrlPSlbecewIu9Ldz6GUvn7aO/v0mKx6PXXX7e2cefjWJHPB3f4WyTcOMGqVas0efJkzZw5U8nJybrrrrs0ePBgZWZmurq0Ktm6dauefPJJ7dy5UwkJCbp69aoGDhyo8+fP27S79957lZWVZb1t3LjRRRVXXocOHWxqT0lJsa577bXXNH/+fC1atEi7d+9WSEiI7rnnHuv3ktUFu3fvttm/hIQESdKDDz5obVPXjt/58+cVFRWlRYsW2V1fkeM2efJkrV27VitXrtRXX32lc+fOaejQocrPz6+t3SiTo/27cOGC9u3bpxdeeEH79u3TmjVrdPjwYcXExJRq+/jjj9sc1/fee682yq+Q8o6hVP770p2PoVT+Phbft6ysLC1btkwWi0UjR460aeeux7Einw9u8bdooNpuv/12Y+LEiTbL2rZtazz//PMuqsi5Tpw4YUgytm7dal02duxYY/jw4a4rqhpeeuklIyoqyu66goICIyQkxHj11Vetyy5dumQEBgYa7777bi1V6HxPP/200apVK6OgoMAwjLp9/AzDMCQZa9eutT6uyHE7c+aM4eXlZaxcudLa5scffzQ8PDyMzz//vNZqr4iS+2fPf/7zH0OSkZGRYV3Wt29f4+mnn67Z4pzE3j6W976sS8fQMCp2HIcPH27cfffdNsvq0nEs+fngLn+L9NxU0+XLl7V3714NHDjQZvnAgQO1fft2F1XlXDk5OZKkxo0b2yxPSkpSUFCQWrdurccff1wnTpxwRXlVcuTIEYWFhSkyMlIPPfSQjh49KklKT09Xdna2zfH08fFR37596+zxvHz5sj755BM99thjNl8WW5ePX0kVOW579+7VlStXbNqEhYWpY8eOdfLY5uTkyGKxqFGjRjbLP/30UzVt2lQdOnTQtGnT6lSPo+T4fWm2Y/jTTz9pw4YN+u1vf1tqXV05jiU/H9zlb/G6++JMZzt58qTy8/MVHBxsszw4OFjZ2dkuqsp5DMNQXFyc7rzzTnXs2NG6fPDgwXrwwQfVokULpaen64UXXtDdd9+tvXv3uv0VN3v06KGPP/5YrVu31k8//aQ//vGP6tWrlw4ePGg9ZvaOZ0ZGhivKrbZ169bpzJkzGjdunHVZXT5+9lTkuGVnZ8vb21s33HBDqTZ17W/10qVLev755/XrX//a5gsJH3nkEUVGRiokJETffPONpk+frgMHDliHJd1dee9LMx1DSfroo4/k7++v+++/32Z5XTmO9j4f3OVvkXDjJMX/RywVHvSSy+qiSZMm6euvv9ZXX31ls3z06NHWnzt27Khu3bqpRYsW2rBhQ6k/VHczePBg68+dOnVSz5491apVK3300UfWyYtmOp5Lly7V4MGDFRYWZl1Wl4+fI1U5bnXt2F65ckUPPfSQCgoKtHjxYpt1jz/+uPXnjh076pZbblG3bt20b98+denSpbZLrbSqvi/r2jEssmzZMj3yyCPy9fW1WV5XjmNZnw+S6/8WGZaqpqZNm8rT07NU2jxx4kSp5FrXPPXUU4qPj1diYqKaNWvmsG1oaKhatGihI0eO1FJ1ztOgQQN16tRJR44csZ41ZZbjmZGRoc2bN2v8+PEO29Xl4yepQsctJCREly9f1unTp8ts4+6uXLmiUaNGKT09XQkJCTa9NvZ06dJFXl5edfa4lnxfmuEYFvnyyy+VlpZW7t+m5J7HsazPB3f5WyTcVJO3t7e6du1aqrswISFBvXr1clFV1WMYhiZNmqQ1a9Zoy5YtioyMLHebU6dO6dixYwoNDa2FCp0rLy9PqampCg0NtXYFFz+ely9f1tatW+vk8Vy+fLmCgoJ03333OWxXl4+fpAodt65du8rLy8umTVZWlr755ps6cWyLgs2RI0e0efNmNWnSpNxtDh48qCtXrtTZ41ryfVnXj2FxS5cuVdeuXRUVFVVuW3c6juV9PrjN36JTpiVf51auXGl4eXkZS5cuNQ4dOmRMnjzZaNCggfHDDz+4urQq+f3vf28EBgYaSUlJRlZWlvV24cIFwzAM4+zZs8bUqVON7du3G+np6UZiYqLRs2dP46abbjJyc3NdXH35pk6daiQlJRlHjx41du7caQwdOtTw9/e3Hq9XX33VCAwMNNasWWOkpKQYDz/8sBEaGlon9q24/Px8o3nz5sZzzz1ns7yuHr+zZ88aycnJRnJysiHJmD9/vpGcnGw9W6gix23ixIlGs2bNjM2bNxv79u0z7r77biMqKsq4evWqq3bLytH+XblyxYiJiTGaNWtm7N+/3+bvMi8vzzAMw/juu++Ml19+2di9e7eRnp5ubNiwwWjbtq3RuXNnt9g/w3C8jxV9X7rzMTSM8t+nhmEYOTk5Rv369Y0lS5aU2t7dj2N5nw+G4R5/i4QbJ3nnnXeMFi1aGN7e3kaXLl1sTpuuayTZvS1fvtwwDMO4cOGCMXDgQOPGG280vLy8jObNmxtjx441MjMzXVt4BY0ePdoIDQ01vLy8jLCwMOP+++83Dh48aF1fUFBgvPTSS0ZISIjh4+Nj9OnTx0hJSXFhxVXzxRdfGJKMtLQ0m+V19fglJibafV+OHTvWMIyKHbeLFy8akyZNMho3bmz4+fkZQ4cOdZv9drR/6enpZf5dJiYmGoZhGJmZmUafPn2Mxo0bG97e3karVq2M2NhY49SpU67dsWIc7WNF35fufAwNo/z3qWEYxnvvvWf4+fkZZ86cKbW9ux/H8j4fDMM9/hYt14oFAAAwBebcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcAAAAUyHcALjuJSUlyWKx6MyZM64uBYATEG4AAICpEG4AAICpEG4AuJxhGHrttdfUsmVL+fn5KSoqSp999pmkX4aMNmzYoKioKPn6+qpHjx5KSUmxeY7Vq1erQ4cO8vHxUUREhN58802b9Xl5eXr22WcVHh4uHx8f3XLLLVq6dKlNm71796pbt26qX7++evXqpbS0tJrdcQA1gnADwOX+8Ic/aPny5VqyZIkOHjyoKVOm6De/+Y22bt1qbfPMM8/ojTfe0O7duxUUFKSYmBhduXJFUmEoGTVqlB566CGlpKRo1qxZeuGFF7RixQrr9o8++qhWrlyphQsXKjU1Ve+++64aNmxoU8fMmTP15ptvas+ePapXr54ee+yxWtl/AM7Ft4IDcKnz58+radOm2rJli3r27GldPn78eF24cEETJkxQdHS0Vq5cqdGjR0uS/vvf/6pZs2ZasWKFRo0apUceeUQ///yzNm3aZN3+2Wef1YYNG3Tw4EEdPnxYbdq0UUJCggYMGFCqhqSkJEVHR2vz5s3q37+/JGnjxo267777dPHiRfn6+tbwbwGAM9FzA8ClDh06pEuXLumee+5Rw4YNrbePP/5Y33//vbVd8eDTuHFjtWnTRqmpqZKk1NRU9e7d2+Z5e/furSNHjig/P1/79++Xp6en+vbt67CWW2+91fpzaGioJOnEiRPV3kcAtaueqwsAcH0rKCiQJG3YsEE33XSTzTofHx+bgFOSxWKRVDhnp+jnIsU7pf38/CpUi5eXV6nnLqoPQN1Bzw0Al2rfvr18fHyUmZmpm2++2eYWHh5ubbdz507rz6dPn9bhw4fVtm1b63N89dVXNs+7fft2tW7dWp6enurUqZMKCgps5vAAMC96bgC4lL+/v6ZNm6YpU6aooKBAd955p3Jzc7V9+3Y1bNhQLVq0kCTNnj1bTZo0UXBwsGbOnKmmTZtqxIgRkqSpU6eqe/fumjNnjkaPHq0dO3Zo0aJFWrx4sSQpIiJCY8eO1WOPPaaFCxcqKipKGRkZOnHihEaNGuWqXQdQQwg3AFxuzpw5CgoK0rx583T06FE1atRIXbp00YwZM6zDQq+++qqefvppHTlyRFFRUYqPj5e3t7ckqUuXLvrb3/6mF198UXPmzFFoaKhmz56tcePGWV9jyZIlmjFjhp544gmdOnVKzZs314wZM1yxuwBqGGdLAXBrRWcynT59Wo0aNXJ1OQDqAObcAAAAUyHcAAAAU2FYCgAAmAo9NwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFQINwAAwFT+P+GMdgYCVxLRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋(여기서는 검증셋)의 오차를 저장합니다.\n",
    "y_vloss = hist['val_loss']\n",
    "\n",
    "# y_loss에 학습셋의 오차를 저장합니다.\n",
    "y_loss = hist['loss']\n",
    "\n",
    "# x 값을 지정하고 테스트셋(검증셋)의 오차를 빨간색으로, 학습셋의 오차를 파란색으로 표시합니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label='Trainset_loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
