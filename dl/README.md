## Deep Learning

- 02 활성화함수
  + Sigmoid
  + Hyperbolic Tangent
  + Rectified Linear Unit (ReLU)
  + Leaky ReLU
  + Softmax 함수

- 03 신경망
![Neuron](https://user-images.githubusercontent.com/114986610/209793333-308e9f4d-8e7f-4575-a719-1572712c0a90.png)

- 04 역전파
  + 출력값과 정답의 오차를 네트워크에서 역전파시켜 네트워크의 가중치와 bias를 최적화시킴
![backpropagation](https://user-images.githubusercontent.com/114986610/209793626-ffafe2d4-699a-4296-b7e3-11f69229cbe2.png)

- 05 경사하강법

![화면 캡처 2022-12-28 185907](https://user-images.githubusercontent.com/114986610/209795179-67b1d299-f704-4d8e-bd6e-ad5d5aae88f7.png)
![화면 캡처 2022-12-28 185918](https://user-images.githubusercontent.com/114986610/209795088-e6b5fb0c-9e88-42e2-9723-94a6c130e1b0.png)
![화면 캡처 2022-12-28 185943](https://user-images.githubusercontent.com/114986610/209795095-534563a8-cc8c-43b7-920d-2e9f735aa84e.png)

- 06 회귀 기울기

- 07 분류 기울기

- 08 경사하강법의 최적화알고리즘

- 09 배치 사이즈
  + 가중치와 bias를 수정하는 간격을 의미
  + 에포크(epoch)
    - 모든 훈련 데이터를 1회 학습하는 것을 1epoch 라 함
  + 배치(batch)
    - 1 에포크는 m개의 배치로 구성됨
  
  ![화면 캡처 2022-12-28 190931](https://user-images.githubusercontent.com/114986610/209795658-e370cf4b-42f5-4469-b62a-4fad7a4e14f7.png)


- 10 행렬연산

- 11 회귀문제구현

- 12 분류문제구현
